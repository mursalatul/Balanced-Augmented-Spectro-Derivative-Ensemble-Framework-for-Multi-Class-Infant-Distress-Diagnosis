{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f63fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from pydub import AudioSegment\n",
    "import warnings\n",
    "import collections\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94424a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Audio Processing Utilities\n",
    "# -----------------------------\n",
    "\n",
    "def convert_to_wav(file_path):\n",
    "    \"\"\"Convert non-WAV files to WAV using pydub.\"\"\"\n",
    "    try:\n",
    "        if file_path.lower().endswith('.wav'):\n",
    "            return file_path\n",
    "        wav_path = os.path.splitext(file_path)[0] + '.wav'\n",
    "        audio = AudioSegment.from_file(file_path)\n",
    "        audio.export(wav_path, format='wav')\n",
    "        return wav_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio, sample_rate):\n",
    "    \"\"\"Extract MFCC-based features along with additional spectral features.\"\"\"\n",
    "    try:\n",
    "        # MFCCs and their derivatives\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        delta = librosa.feature.delta(mfccs)\n",
    "        delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "        \n",
    "        # Additional spectral features\n",
    "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate))\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate))\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio))\n",
    "        \n",
    "        features = np.hstack([\n",
    "            np.mean(mfccs.T, axis=0),\n",
    "            np.std(mfccs.T, axis=0),\n",
    "            np.max(mfccs.T, axis=0),\n",
    "            np.mean(delta.T, axis=0),\n",
    "            np.mean(delta2.T, axis=0),\n",
    "            spectral_centroid,\n",
    "            spectral_rolloff,\n",
    "            zero_crossing_rate\n",
    "        ])\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_audio(audio, sr):\n",
    "    \"\"\"Return list of augmented audio versions.\"\"\"\n",
    "    return [\n",
    "        librosa.effects.pitch_shift(audio, sr=sr, n_steps=random.uniform(-2, 2)),\n",
    "        librosa.effects.time_stretch(audio, rate=random.uniform(0.9, 1.1)),\n",
    "        audio + 0.005 * np.random.randn(len(audio))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38944f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Dataset Preparation\n",
    "# -----------------------------\n",
    "\n",
    "def balance_dataset_with_augmentation(folder_names, base_path=\".\"):\n",
    "    \"\"\"\n",
    "    Load and balance dataset by augmenting minority classes\n",
    "    to match the size of the majority class.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    class_files = {}\n",
    "\n",
    "    for label, folder in enumerate(folder_names):\n",
    "        path = os.path.join(base_path, folder)\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        files = [f for f in os.listdir(path) if f.lower().endswith(('.wav', '.mp3', '.m4a', '.ogg'))]\n",
    "        class_counts[label] = len(files)\n",
    "        class_files[label] = files\n",
    "\n",
    "    max_class = max(class_counts, key=class_counts.get)\n",
    "    max_samples = class_counts[max_class]\n",
    "    print(f\"\\nðŸ“Œ Max class: {folder_names[max_class]} with {max_samples} samples.\")\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for label, files in class_files.items():\n",
    "        folder_path = os.path.join(base_path, folder_names[label])\n",
    "        current_features = []\n",
    "\n",
    "        for file in files:\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            wav_path = convert_to_wav(file_path)\n",
    "            if not wav_path:\n",
    "                continue\n",
    "            try:\n",
    "                audio, sr = librosa.load(wav_path, res_type='kaiser_fast')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {wav_path}: {e}\")\n",
    "                continue\n",
    "            features = extract_features(audio, sr)\n",
    "            if features is not None:\n",
    "                current_features.append(features)\n",
    "\n",
    "        X.extend(current_features)\n",
    "        y.extend([label] * len(current_features))\n",
    "\n",
    "        # Augment data for minority classes\n",
    "        if label == max_class:\n",
    "            continue\n",
    "\n",
    "        current_count = len(current_features)\n",
    "        while current_count < max_samples:\n",
    "            for file in files:\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                wav_path = convert_to_wav(file_path)\n",
    "                if not wav_path:\n",
    "                    continue\n",
    "                try:\n",
    "                    audio, sr = librosa.load(wav_path, res_type='kaiser_fast')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {wav_path}: {e}\")\n",
    "                    continue\n",
    "                for aug_audio in augment_audio(audio, sr):\n",
    "                    aug_features = extract_features(aug_audio, sr)\n",
    "                    if aug_features is not None:\n",
    "                        X.append(aug_features)\n",
    "                        y.append(label)\n",
    "                        current_count += 1\n",
    "                    if current_count >= max_samples:\n",
    "                        break\n",
    "                if current_count >= max_samples:\n",
    "                    break\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Model Training\n",
    "# -----------------------------\n",
    "\n",
    "def train_model(model, X_train, X_test, y_train, y_test, scaler=None):\n",
    "    \"\"\"Generic model trainer and evaluator.\"\"\"\n",
    "    if scaler:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return model, acc, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Main Pipeline\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    # No fixed seeds here to allow variability in each run\n",
    "    folder_names = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "    print(\"ðŸ“¦ Preparing balanced dataset with augmentation...\")\n",
    "    X, y = balance_dataset_with_augmentation(folder_names)\n",
    "\n",
    "    # Show class distribution\n",
    "    label_counts = collections.Counter(y)\n",
    "    print(\"\\nðŸ“Š Class distribution after augmentation:\")\n",
    "    for label, count in sorted(label_counts.items()):\n",
    "        print(f\"{folder_names[label]}: {count}\")\n",
    "\n",
    "    # Split the dataset without a fixed random state\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y\n",
    "    )\n",
    "    print(f\"\\nðŸ”¹ Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "    print(f\"ðŸ”¹ Feature size: {X.shape[1]}\")\n",
    "\n",
    "    # SVM is tuned using GridSearchCV with a small parameter grid.\n",
    "    svm_model = SVC(kernel='rbf')\n",
    "    param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']}\n",
    "    svm_grid = GridSearchCV(svm_model, param_grid, cv=3)\n",
    "    \n",
    "    models = {\n",
    "        'Random Forest': (RandomForestClassifier(), None),\n",
    "        'XGBoost': (XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss'), None),\n",
    "        'SVM (RBF)': (svm_grid, StandardScaler()),\n",
    "        'Logistic Regression': (LogisticRegression(max_iter=1000), StandardScaler()),\n",
    "        'k-NN': (KNeighborsClassifier(n_neighbors=5), StandardScaler()),\n",
    "        'Gradient Boosting': (GradientBoostingClassifier(), None),\n",
    "        'Naive Bayes': (GaussianNB(), None),\n",
    "        'MLP': (MLPClassifier(hidden_layer_sizes=(100,), max_iter=500), StandardScaler())\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    trained_models = {}\n",
    "\n",
    "    for name, (model, scaler) in models.items():\n",
    "        print(f\"\\nðŸš€ Training {name}...\")\n",
    "        trained_model, acc, trained_scaler = train_model(model, X_train, X_test, y_train, y_test, scaler)\n",
    "        results[name] = acc\n",
    "        trained_models[name] = (trained_model, trained_scaler)\n",
    "        print(f\"{name} Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "    print(\"\\nðŸ“ˆ Final Model Accuracies (sorted):\")\n",
    "    for name, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{name}: {acc * 100:.2f}%\")\n",
    "\n",
    "    def predict_audio(file_path, model, scaler=None):\n",
    "        wav_path = convert_to_wav(file_path)\n",
    "        if not wav_path:\n",
    "            return \"Invalid audio\"\n",
    "        audio, sr = librosa.load(wav_path, res_type='kaiser_fast')\n",
    "        features = extract_features(audio, sr)\n",
    "        if features is None:\n",
    "            return \"Could not extract features\"\n",
    "        features = [features]\n",
    "        if scaler:\n",
    "            features = scaler.transform(features)\n",
    "        pred = model.predict(features)[0]\n",
    "        return folder_names[pred]\n",
    "\n",
    "    return results, trained_models, predict_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d9cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Entry Point\n",
    "# -----------------------------\n",
    "results, trained_models, predict_func = main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
