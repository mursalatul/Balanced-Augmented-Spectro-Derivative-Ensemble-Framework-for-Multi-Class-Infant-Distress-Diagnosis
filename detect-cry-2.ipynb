{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "üìà Final Model Accuracies (sorted):\n",
    "XGBoost: 96.34%\n",
    "Random Forest: 96.07%\n",
    "SVM (RBF): 96.07%\n",
    "MLP: 93.98%\n",
    "Gradient Boosting: 93.46%\n",
    "Logistic Regression: 90.05%\n",
    "k-NN: 83.77%\n",
    "Naive Bayes: 67.54%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from pydub import AudioSegment\n",
    "import warnings\n",
    "import collections\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Audio Processing Utilities\n",
    "# -----------------------------\n",
    "\n",
    "def convert_to_wav(file_path):\n",
    "    \"\"\"Convert non-WAV files to WAV using pydub.\"\"\"\n",
    "    try:\n",
    "        if file_path.lower().endswith('.wav'):\n",
    "            return file_path\n",
    "        wav_path = os.path.splitext(file_path)[0] + '.wav'\n",
    "        audio = AudioSegment.from_file(file_path)\n",
    "        audio.export(wav_path, format='wav')\n",
    "        return wav_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio, sample_rate):\n",
    "    \"\"\"Extract MFCC-based features including deltas.\"\"\"\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        delta = librosa.feature.delta(mfccs)\n",
    "        delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "        features = np.hstack([\n",
    "            np.mean(mfccs.T, axis=0),\n",
    "            np.std(mfccs.T, axis=0),\n",
    "            np.max(mfccs.T, axis=0),\n",
    "            np.mean(delta.T, axis=0),\n",
    "            np.mean(delta2.T, axis=0)\n",
    "        ])\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_audio(audio, sr):\n",
    "    \"\"\"Return list of augmented audio versions.\"\"\"\n",
    "    return [\n",
    "        librosa.effects.pitch_shift(audio, sr=sr, n_steps=random.uniform(-2, 2)),\n",
    "        librosa.effects.time_stretch(audio, rate=random.uniform(0.9, 1.1)),\n",
    "        audio + 0.005 * np.random.randn(len(audio))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Dataset Preparation\n",
    "# -----------------------------\n",
    "\n",
    "def balance_dataset_with_augmentation(folder_names, base_path=\".\"):\n",
    "    \"\"\"\n",
    "    Load and balance dataset by augmenting minority classes\n",
    "    to match the size of the majority class.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    class_files = {}\n",
    "\n",
    "    for label, folder in enumerate(folder_names):\n",
    "        path = os.path.join(base_path, folder)\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        files = [f for f in os.listdir(path) if f.lower().endswith(('.wav', '.mp3', '.m4a', '.ogg'))]\n",
    "        class_counts[label] = len(files)\n",
    "        class_files[label] = files\n",
    "\n",
    "    max_class = max(class_counts, key=class_counts.get)\n",
    "    max_samples = class_counts[max_class]\n",
    "    print(f\"\\nüìå Max class: {folder_names[max_class]} with {max_samples} samples.\")\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for label, files in class_files.items():\n",
    "        folder_path = os.path.join(base_path, folder_names[label])\n",
    "        current_features = []\n",
    "\n",
    "        for file in files:\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            wav_path = convert_to_wav(file_path)\n",
    "            if not wav_path:\n",
    "                continue\n",
    "            try:\n",
    "                audio, sr = librosa.load(wav_path, res_type='kaiser_fast')\n",
    "            except:\n",
    "                continue\n",
    "            features = extract_features(audio, sr)\n",
    "            if features is not None:\n",
    "                current_features.append(features)\n",
    "\n",
    "        X.extend(current_features)\n",
    "        y.extend([label] * len(current_features))\n",
    "\n",
    "        if label == max_class:\n",
    "            continue\n",
    "\n",
    "        current_count = len(current_features)\n",
    "        while current_count < max_samples:\n",
    "            for file in files:\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                wav_path = convert_to_wav(file_path)\n",
    "                if not wav_path:\n",
    "                    continue\n",
    "                try:\n",
    "                    audio, sr = librosa.load(wav_path, res_type='kaiser_fast')\n",
    "                except:\n",
    "                    continue\n",
    "                for aug_audio in augment_audio(audio, sr):\n",
    "                    aug_features = extract_features(aug_audio, sr)\n",
    "                    if aug_features is not None:\n",
    "                        X.append(aug_features)\n",
    "                        y.append(label)\n",
    "                        current_count += 1\n",
    "                    if current_count >= max_samples:\n",
    "                        break\n",
    "                if current_count >= max_samples:\n",
    "                    break\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Model Training\n",
    "# -----------------------------\n",
    "\n",
    "def train_model(model, X_train, X_test, y_train, y_test, scaler=None):\n",
    "    \"\"\"Generic model trainer and evaluator.\"\"\"\n",
    "    if scaler:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return model, acc, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Main Pipeline\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    folder_names = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "    print(\"üì¶ Preparing balanced dataset with augmentation...\")\n",
    "    X, y = balance_dataset_with_augmentation(folder_names)\n",
    "\n",
    "    # Show class distribution\n",
    "    label_counts = collections.Counter(y)\n",
    "    print(\"\\nüìä Class distribution after augmentation:\")\n",
    "    for label, count in sorted(label_counts.items()):\n",
    "        print(f\"{folder_names[label]}: {count}\")\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    print(f\"\\nüîπ Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "    print(f\"üîπ Feature size: {X.shape[1]}\")\n",
    "\n",
    "    # Models\n",
    "    models = {\n",
    "        'Random Forest': (RandomForestClassifier(random_state=42), None),\n",
    "        'XGBoost': (XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss', random_state=42), None),\n",
    "        'SVM (RBF)': (SVC(kernel='rbf', random_state=42), StandardScaler()),\n",
    "        'Logistic Regression': (LogisticRegression(max_iter=1000, random_state=42), StandardScaler()),\n",
    "        'k-NN': (KNeighborsClassifier(n_neighbors=5), StandardScaler()),\n",
    "        'Gradient Boosting': (GradientBoostingClassifier(random_state=42), None),\n",
    "        'Naive Bayes': (GaussianNB(), None),\n",
    "        'MLP': (MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42), StandardScaler())\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    trained_models = {}\n",
    "\n",
    "    for name, (model, scaler) in models.items():\n",
    "        print(f\"\\nüöÄ Training {name}...\")\n",
    "        trained_model, acc, trained_scaler = train_model(model, X_train, X_test, y_train, y_test, scaler)\n",
    "        results[name] = acc\n",
    "        trained_models[name] = (trained_model, trained_scaler)\n",
    "        print(f\"{name} Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "    print(\"\\nüìà Final Model Accuracies (sorted):\")\n",
    "    for name, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{name}: {acc * 100:.2f}%\")\n",
    "\n",
    "    def predict_audio(file_path, model, scaler=None):\n",
    "        wav_path = convert_to_wav(file_path)\n",
    "        if not wav_path:\n",
    "            return \"Invalid audio\"\n",
    "        audio, sr = librosa.load(wav_path, res_type='kaiser_fast')\n",
    "        features = extract_features(audio, sr)\n",
    "        if features is None:\n",
    "            return \"Could not extract features\"\n",
    "        features = [features]\n",
    "        if scaler:\n",
    "            features = scaler.transform(features)\n",
    "        pred = model.predict(features)[0]\n",
    "        return folder_names[pred]\n",
    "\n",
    "    return trained_models, predict_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Entry Point\n",
    "# -----------------------------\n",
    "trained_models, predict_func = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"D:\\defence\\model\\donateacry_corpus_cleaned_and_updated_data\\\\tired\\\\7A22229D-06C2-4AAA-9674-DE5DF1906B3A-1436891957-1.1-m-72-ti.wav\"\n",
    "print(f\"\\nüîç Prediction Results for: {test_file}\")\n",
    "for name, (model, scaler) in trained_models.items():\n",
    "    prediction = predict_func(test_file, model, scaler)\n",
    "    print(f\"{name}: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
