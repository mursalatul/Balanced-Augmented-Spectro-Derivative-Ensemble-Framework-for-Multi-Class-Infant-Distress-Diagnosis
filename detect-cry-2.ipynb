{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n📈 Final Model Accuracies (sorted):\\nXGBoost: 96.34%\\nRandom Forest: 96.07%\\nSVM (RBF): 96.07%\\nMLP: 93.98%\\nGradient Boosting: 93.46%\\nLogistic Regression: 90.05%\\nk-NN: 83.77%\\nNaive Bayes: 67.54%\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "📈 Final Model Accuracies (sorted):\n",
    "XGBoost: 96.34%\n",
    "Random Forest: 96.07%\n",
    "SVM (RBF): 96.07%\n",
    "MLP: 93.98%\n",
    "Gradient Boosting: 93.46%\n",
    "Logistic Regression: 90.05%\n",
    "k-NN: 83.77%\n",
    "Naive Bayes: 67.54%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from pydub import AudioSegment\n",
    "import warnings\n",
    "import collections\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(trained_models, results, output_dir=\".\"):\n",
    "    \"\"\"\n",
    "    Saves the model with the highest accuracy from the results dict\n",
    "    as 'infant_cry_detection_classifier_model.pkl'.\n",
    "    \n",
    "    Parameters:\n",
    "    - trained_models: dict of {model_name: (model, scaler)}\n",
    "    - results: dict of {model_name: accuracy}\n",
    "    - output_dir: directory to save the model (default: current directory)\n",
    "    \n",
    "    Returns:\n",
    "    - saved_path: full path to saved model\n",
    "    - best_model_name: name of the best model\n",
    "    \"\"\"\n",
    "    best_model_name = max(results, key=results.get)\n",
    "    best_model, best_scaler = trained_models[best_model_name]\n",
    "    \n",
    "    filename = \"infant_cry_detection_classifier_model.pkl\"\n",
    "    saved_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    with open(saved_path, 'wb') as f:\n",
    "        pickle.dump((best_model, best_scaler), f)\n",
    "\n",
    "    print(f\"\\n✅ Best model '{best_model_name}' saved as: {saved_path}\")\n",
    "    return saved_path, best_model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Audio Processing Utilities\n",
    "# -----------------------------\n",
    "\n",
    "def convert_to_wav(file_path):\n",
    "    \"\"\"Convert non-WAV files to WAV using pydub.\"\"\"\n",
    "    try:\n",
    "        if file_path.lower().endswith('.wav'):\n",
    "            return file_path\n",
    "        wav_path = os.path.splitext(file_path)[0] + '.wav'\n",
    "        audio = AudioSegment.from_file(file_path)\n",
    "        audio.export(wav_path, format='wav')\n",
    "        return wav_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio, sample_rate):\n",
    "    \"\"\"Extract MFCC-based features including deltas.\"\"\"\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        delta = librosa.feature.delta(mfccs)\n",
    "        delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "        features = np.hstack([\n",
    "            np.mean(mfccs.T, axis=0),\n",
    "            np.std(mfccs.T, axis=0),\n",
    "            np.max(mfccs.T, axis=0),\n",
    "            np.mean(delta.T, axis=0),\n",
    "            np.mean(delta2.T, axis=0)\n",
    "        ])\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_audio(audio, sr):\n",
    "    \"\"\"Return list of augmented audio versions.\"\"\"\n",
    "    return [\n",
    "        librosa.effects.pitch_shift(audio, sr=sr, n_steps=random.uniform(-2, 2)),\n",
    "        librosa.effects.time_stretch(audio, rate=random.uniform(0.9, 1.1)),\n",
    "        audio + 0.005 * np.random.randn(len(audio))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Dataset Preparation\n",
    "# -----------------------------\n",
    "\n",
    "def balance_dataset_with_augmentation(folder_names, base_path=\".\"):\n",
    "    \"\"\"\n",
    "    Load and balance dataset by augmenting minority classes\n",
    "    to match the size of the majority class.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    class_files = {}\n",
    "\n",
    "    for label, folder in enumerate(folder_names):\n",
    "        path = os.path.join(base_path, folder)\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        files = [f for f in os.listdir(path) if f.lower().endswith(('.wav', '.mp3', '.m4a', '.ogg'))]\n",
    "        class_counts[label] = len(files)\n",
    "        class_files[label] = files\n",
    "\n",
    "    max_class = max(class_counts, key=class_counts.get)\n",
    "    max_samples = class_counts[max_class]\n",
    "    print(f\"\\n📌 Max class: {folder_names[max_class]} with {max_samples} samples.\")\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for label, files in class_files.items():\n",
    "        folder_path = os.path.join(base_path, folder_names[label])\n",
    "        current_features = []\n",
    "\n",
    "        for file in files:\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            wav_path = convert_to_wav(file_path)\n",
    "            if not wav_path:\n",
    "                continue\n",
    "            try:\n",
    "                audio, sr = librosa.load(wav_path, res_type='kaiser_fast')\n",
    "            except:\n",
    "                continue\n",
    "            features = extract_features(audio, sr)\n",
    "            if features is not None:\n",
    "                current_features.append(features)\n",
    "\n",
    "        X.extend(current_features)\n",
    "        y.extend([label] * len(current_features))\n",
    "\n",
    "        if label == max_class:\n",
    "            continue\n",
    "\n",
    "        current_count = len(current_features)\n",
    "        while current_count < max_samples:\n",
    "            for file in files:\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                wav_path = convert_to_wav(file_path)\n",
    "                if not wav_path:\n",
    "                    continue\n",
    "                try:\n",
    "                    audio, sr = librosa.load(wav_path, res_type='kaiser_fast')\n",
    "                except:\n",
    "                    continue\n",
    "                for aug_audio in augment_audio(audio, sr):\n",
    "                    aug_features = extract_features(aug_audio, sr)\n",
    "                    if aug_features is not None:\n",
    "                        X.append(aug_features)\n",
    "                        y.append(label)\n",
    "                        current_count += 1\n",
    "                    if current_count >= max_samples:\n",
    "                        break\n",
    "                if current_count >= max_samples:\n",
    "                    break\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Model Training\n",
    "# -----------------------------\n",
    "\n",
    "def train_model(model, X_train, X_test, y_train, y_test, scaler=None):\n",
    "    \"\"\"Generic model trainer and evaluator.\"\"\"\n",
    "    if scaler:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return model, acc, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Main Pipeline\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    folder_names = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "    print(\"📦 Preparing balanced dataset with augmentation...\")\n",
    "    X, y = balance_dataset_with_augmentation(folder_names)\n",
    "\n",
    "    # Show class distribution\n",
    "    label_counts = collections.Counter(y)\n",
    "    print(\"\\n📊 Class distribution after augmentation:\")\n",
    "    for label, count in sorted(label_counts.items()):\n",
    "        print(f\"{folder_names[label]}: {count}\")\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    print(f\"\\n🔹 Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "    print(f\"🔹 Feature size: {X.shape[1]}\")\n",
    "\n",
    "    # Models\n",
    "    models = {\n",
    "        'Random Forest': (RandomForestClassifier(random_state=42), None),\n",
    "        'XGBoost': (XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss', random_state=42), None),\n",
    "        'SVM (RBF)': (SVC(kernel='rbf', random_state=42), StandardScaler()),\n",
    "        'Logistic Regression': (LogisticRegression(max_iter=1000, random_state=42), StandardScaler()),\n",
    "        'k-NN': (KNeighborsClassifier(n_neighbors=5), StandardScaler()),\n",
    "        'Gradient Boosting': (GradientBoostingClassifier(random_state=42), None),\n",
    "        'Naive Bayes': (GaussianNB(), None),\n",
    "        'MLP': (MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42), StandardScaler())\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    trained_models = {}\n",
    "\n",
    "    for name, (model, scaler) in models.items():\n",
    "        print(f\"\\n🚀 Training {name}...\")\n",
    "        trained_model, acc, trained_scaler = train_model(model, X_train, X_test, y_train, y_test, scaler)\n",
    "        results[name] = acc\n",
    "        trained_models[name] = (trained_model, trained_scaler)\n",
    "        print(f\"{name} Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "    print(\"\\n📈 Final Model Accuracies (sorted):\")\n",
    "    for name, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{name}: {acc * 100:.2f}%\")\n",
    "\n",
    "    # save the best model for use it without train everytime\n",
    "    save_best_model(trained_models, results)\n",
    "\n",
    "\n",
    "    def predict_audio(file_path, model, scaler=None):\n",
    "        wav_path = convert_to_wav(file_path)\n",
    "        if not wav_path:\n",
    "            return \"Invalid audio\"\n",
    "        audio, sr = librosa.load(wav_path, res_type='kaiser_fast')\n",
    "        features = extract_features(audio, sr)\n",
    "        if features is None:\n",
    "            return \"Could not extract features\"\n",
    "        features = [features]\n",
    "        if scaler:\n",
    "            features = scaler.transform(features)\n",
    "        pred = model.predict(features)[0]\n",
    "        return folder_names[pred]\n",
    "\n",
    "    return trained_models, predict_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Preparing balanced dataset with augmentation...\n",
      "\n",
      "📌 Max class: hungry with 382 samples.\n",
      "\n",
      "📊 Class distribution after augmentation:\n",
      "belly_pain: 382\n",
      "burping: 382\n",
      "discomfort: 382\n",
      "hungry: 382\n",
      "tired: 382\n",
      "\n",
      "🔹 Train size: 1528, Test size: 382\n",
      "🔹 Feature size: 200\n",
      "\n",
      "🚀 Training Random Forest...\n",
      "Random Forest Accuracy: 98.17%\n",
      "\n",
      "🚀 Training XGBoost...\n",
      "XGBoost Accuracy: 96.86%\n",
      "\n",
      "🚀 Training SVM (RBF)...\n",
      "SVM (RBF) Accuracy: 97.91%\n",
      "\n",
      "🚀 Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 90.84%\n",
      "\n",
      "🚀 Training k-NN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"d:\\defence\\model\\donateacry_corpus_cleaned_and_updated_data\\.conda\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"d:\\defence\\model\\donateacry_corpus_cleaned_and_updated_data\\.conda\\lib\\subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"d:\\defence\\model\\donateacry_corpus_cleaned_and_updated_data\\.conda\\lib\\subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"d:\\defence\\model\\donateacry_corpus_cleaned_and_updated_data\\.conda\\lib\\subprocess.py\", line 1456, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 84.55%\n",
      "\n",
      "🚀 Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 94.76%\n",
      "\n",
      "🚀 Training Naive Bayes...\n",
      "Naive Bayes Accuracy: 67.54%\n",
      "\n",
      "🚀 Training MLP...\n",
      "MLP Accuracy: 94.24%\n",
      "\n",
      "📈 Final Model Accuracies (sorted):\n",
      "Random Forest: 98.17%\n",
      "SVM (RBF): 97.91%\n",
      "XGBoost: 96.86%\n",
      "Gradient Boosting: 94.76%\n",
      "MLP: 94.24%\n",
      "Logistic Regression: 90.84%\n",
      "k-NN: 84.55%\n",
      "Naive Bayes: 67.54%\n",
      "\n",
      "✅ Best model 'Random Forest' saved as: .\\infant_cry_detection_classifier_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Entry Point\n",
    "# -----------------------------\n",
    "trained_models, predict_func = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Prediction Results for: D:\\defence\\model\\donateacry_corpus_cleaned_and_updated_data\\discomfort\\1309B82C-F146-46F0-A723-45345AFA6EA8-1432801693-1.1-f-26-dc.wav\n",
      "Random Forest: discomfort\n",
      "XGBoost: discomfort\n",
      "SVM (RBF): discomfort\n",
      "Logistic Regression: discomfort\n",
      "k-NN: discomfort\n",
      "Gradient Boosting: discomfort\n",
      "Naive Bayes: discomfort\n",
      "MLP: discomfort\n"
     ]
    }
   ],
   "source": [
    "test_file = \"D:\\defence\\model\\donateacry_corpus_cleaned_and_updated_data\\discomfort\\\\1309B82C-F146-46F0-A723-45345AFA6EA8-1432801693-1.1-f-26-dc.wav\"\n",
    "print(f\"\\n🔍 Prediction Results for: {test_file}\")\n",
    "for name, (model, scaler) in trained_models.items():\n",
    "    prediction = predict_func(test_file, model, scaler)\n",
    "    print(f\"{name}: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
